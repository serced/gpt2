# Code to understand and train your own GPT2 without much background

I started this blogpost under `yourGPT.ipynb` for people without little or no background in AI and/or software. It serves as an introduction to large language modelling (LLM). 

The repository also contains the code I used to train a slightly larger model on lighting.ai. However, the models are not very optimized and the intended purposes of them are largely educational.  
